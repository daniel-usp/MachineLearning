{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-usp/MachineLearning/blob/main/04%20-%20DecisionTrees/Prompt_DecisionTreeClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def importar_bibliotecas():\n",
        "    \"\"\"\n",
        "    Importa todas as bibliotecas necessárias para o projeto.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "    from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "    from sklearn.metrics import accuracy_score, classification_report\n",
        "    import matplotlib.pyplot as plt\n",
        "    import graphviz\n",
        "\n",
        "def carregar_dados(url):\n",
        "    \"\"\"\n",
        "    Carrega os dados a partir de uma URL específica.\n",
        "\n",
        "    Parameters:\n",
        "    url (str): URL do arquivo Excel contendo os dados.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame contendo os dados carregados.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        dados = pd.read_excel(url)\n",
        "        print(\"Dados carregados com sucesso.\")\n",
        "        return dados\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar os dados: {e}\")\n",
        "\n",
        "def preprocessar_dados(dados, coluna_alvo):\n",
        "    \"\"\"\n",
        "    Separa os dados em variáveis independentes (X) e variável dependente (y).\n",
        "\n",
        "    Parameters:\n",
        "    dados (pd.DataFrame): DataFrame contendo os dados.\n",
        "    coluna_alvo (str): Nome da coluna alvo.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Contendo X e y.\n",
        "    \"\"\"\n",
        "    y = dados[coluna_alvo]\n",
        "    X = dados.drop(coluna_alvo, axis=1)\n",
        "    print(\"Dados pré-processados.\")\n",
        "    return X, y\n",
        "\n",
        "def dividir_dados(X, y, teste_size=0.3, random_state=42):\n",
        "    \"\"\"\n",
        "    Divide os dados em conjuntos de treino e teste.\n",
        "\n",
        "    Parameters:\n",
        "    X (pd.DataFrame): Variáveis independentes.\n",
        "    y (pd.Series): Variável dependente.\n",
        "    teste_size (float): Proporção dos dados para teste.\n",
        "    random_state (int): Semente para reprodutibilidade.\n",
        "\n",
        "    Returns:\n",
        "    tuple: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=teste_size, random_state=random_state)\n",
        "    print(f\"Dados divididos: {len(X_train)} para treino e {len(X_test)} para teste.\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "def ajustar_hiperparametros(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Realiza a busca em grade para encontrar os melhores hiperparâmetros.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (pd.DataFrame): Dados de treino.\n",
        "    y_train (pd.Series): Rótulos de treino.\n",
        "\n",
        "    Returns:\n",
        "    dict: Melhores parâmetros encontrados.\n",
        "    float: Melhor acurácia durante a validação cruzada.\n",
        "    \"\"\"\n",
        "    param_grid = {\n",
        "        'max_depth': list(range(1, 11)) + [15],\n",
        "        'splitter': ['best', 'random']\n",
        "    }\n",
        "\n",
        "    grid_search = GridSearchCV(\n",
        "        DecisionTreeClassifier(random_state=42),\n",
        "        param_grid,\n",
        "        cv=5,\n",
        "        scoring='accuracy'\n",
        "    )\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    best_params = grid_search.best_params_\n",
        "    best_accuracy = grid_search.best_score_\n",
        "\n",
        "    print(f\"Melhores parâmetros encontrados: {best_params}\")\n",
        "    print(f\"Melhor acurácia na validação cruzada: {best_accuracy:.2f}\")\n",
        "\n",
        "    return best_params, best_accuracy\n",
        "\n",
        "def treinar_modelo(X_train, y_train, params):\n",
        "    \"\"\"\n",
        "    Treina o modelo de Árvore de Decisão com os melhores parâmetros.\n",
        "\n",
        "    Parameters:\n",
        "    X_train (pd.DataFrame): Dados de treino.\n",
        "    y_train (pd.Series): Rótulos de treino.\n",
        "    params (dict): Parâmetros para o modelo.\n",
        "\n",
        "    Returns:\n",
        "    DecisionTreeClassifier: Modelo treinado.\n",
        "    \"\"\"\n",
        "    tree = DecisionTreeClassifier(\n",
        "        max_depth=params['max_depth'],\n",
        "        splitter=params['splitter'],\n",
        "        random_state=42\n",
        "    )\n",
        "    tree.fit(X_train, y_train)\n",
        "    print(\"Modelo treinado com sucesso.\")\n",
        "    return tree\n",
        "\n",
        "def avaliar_modelo(modelo, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Avalia o modelo treinado nos dados de teste.\n",
        "\n",
        "    Parameters:\n",
        "    modelo (DecisionTreeClassifier): Modelo treinado.\n",
        "    X_test (pd.DataFrame): Dados de teste.\n",
        "    y_test (pd.Series): Rótulos de teste.\n",
        "\n",
        "    Returns:\n",
        "    float: Acurácia do modelo.\n",
        "    str: Relatório de classificação.\n",
        "    \"\"\"\n",
        "    y_pred = modelo.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=['Não Cancelou', 'Cancelou'])\n",
        "\n",
        "    print(f\"Taxa de acerto no conjunto de teste: {accuracy:.2f}\")\n",
        "    print(\"Relatório de Classificação:\")\n",
        "    print(report)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "def visualizar_arvore(modelo, feature_names, class_names, arquivo_saida=\"decision_tree\"):\n",
        "    \"\"\"\n",
        "    Exporta e visualiza a árvore de decisão utilizando Graphviz.\n",
        "\n",
        "    Parameters:\n",
        "    modelo (DecisionTreeClassifier): Modelo treinado.\n",
        "    feature_names (list): Lista de nomes das características.\n",
        "    class_names (list): Lista de nomes das classes.\n",
        "    arquivo_saida (str): Nome do arquivo de saída para a árvore.\n",
        "    \"\"\"\n",
        "    dot_data = export_graphviz(\n",
        "        modelo,\n",
        "        out_file=None,\n",
        "        feature_names=feature_names,\n",
        "        class_names=class_names,\n",
        "        filled=True,\n",
        "        rounded=True,\n",
        "        special_characters=True\n",
        "    )\n",
        "\n",
        "    graph = graphviz.Source(dot_data)\n",
        "    graph.render(arquivo_saida)\n",
        "    print(f\"Árvore de decisão salva como {arquivo_saida}.pdf\")\n",
        "    graph.view()\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Função principal que executa todas as etapas do projeto.\n",
        "    \"\"\"\n",
        "    # URL do dataset\n",
        "    url = 'https://github.com/daniel-usp/MachineLearning/raw/main/04%20-%20DecisionTrees/assinatura.xlsx'\n",
        "\n",
        "    # Passo 1: Carregar os dados\n",
        "    dados = carregar_dados(url)\n",
        "\n",
        "    # Passo 2: Pré-processar os dados\n",
        "    X, y = preprocessar_dados(dados, 'cancel')\n",
        "\n",
        "    # Passo 3: Dividir os dados\n",
        "    X_train, X_test, y_train, y_test = dividir_dados(X, y)\n",
        "\n",
        "    # Passo 4: Ajustar hiperparâmetros\n",
        "    melhores_params, melhor_acuracia = ajustar_hiperparametros(X_train, y_train)\n",
        "\n",
        "    # Passo 5: Treinar o modelo\n",
        "    modelo = treinar_modelo(X_train, y_train, melhores_params)\n",
        "\n",
        "    # Passo 6: Avaliar o modelo\n",
        "    acuracia, relatorio = avaliar_modelo(modelo, X_test, y_test)\n",
        "\n",
        "    # Passo 7: Visualizar a árvore de decisão\n",
        "    visualizar_arvore(modelo, X.columns, ['Não Cancelou', 'Cancelou'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "WR5WsSLis3YN",
        "outputId": "fb280093-744f-47da-952c-b95b886f39df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados carregados com sucesso.\n",
            "Dados pré-processados.\n",
            "Dados divididos: 1399 para treino e 600 para teste.\n",
            "Melhores parâmetros encontrados: {'max_depth': 3, 'splitter': 'random'}\n",
            "Melhor acurácia na validação cruzada: 0.78\n",
            "Modelo treinado com sucesso.\n",
            "Taxa de acerto no conjunto de teste: 0.80\n",
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "Não Cancelou       0.84      0.91      0.87       457\n",
            "    Cancelou       0.61      0.44      0.51       143\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.72      0.68      0.69       600\n",
            "weighted avg       0.78      0.80      0.79       600\n",
            "\n",
            "Árvore de decisão salva como decision_tree.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import graphviz\n",
        "\n",
        "# Carregar o banco de dados\n",
        "dados = pd.read_excel('https://github.com/daniel-usp/MachineLearning/raw/main/04%20-%20DecisionTrees/assinatura.xlsx')\n",
        "\n",
        "# Definir X e y\n",
        "y = dados['cancel']\n",
        "X = dados.drop('cancel', axis=1)\n",
        "\n",
        "# Separar amostra treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Definir a grade de parâmetros\n",
        "param_grid = {\n",
        "    'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15],\n",
        "    'splitter': ['best', 'random']\n",
        "}\n",
        "\n",
        "# Realizar a busca em grade (grid search) para encontrar os melhores parâmetros\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Obter os melhores parâmetros\n",
        "best_params = grid_search.best_params_\n",
        "best_max_depth = best_params['max_depth']\n",
        "best_splitter = best_params['splitter']\n",
        "best_accuracy = grid_search.best_score_\n",
        "\n",
        "print(f\"O melhor valor de max_depth é: {best_max_depth}\")\n",
        "print(f\"O melhor valor de splitter é: {best_splitter}\")\n",
        "print(f\"A melhor acurácia durante a validação cruzada é: {best_accuracy:.2f}\")\n",
        "\n",
        "# Treinar o modelo de Árvore de Decisão com os melhores parâmetros\n",
        "tree = DecisionTreeClassifier(max_depth=best_max_depth, splitter=best_splitter, random_state=42)\n",
        "tree.fit(X_train, y_train)\n",
        "\n",
        "# Prever y no conjunto de teste\n",
        "y_pred = tree.predict(X_test)\n",
        "\n",
        "# Avaliar a taxa de acerto fora da amostra\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Taxa de acerto fora da amostra: {accuracy:.2f}\")\n",
        "\n",
        "# Gerar o relatório de classificação\n",
        "report = classification_report(y_test, y_pred, target_names=['0', '1'])\n",
        "print(report)\n",
        "\n",
        "\n",
        "# Exportar a árvore de decisão para o formato Graphviz\n",
        "dot_data = export_graphviz(\n",
        "    tree,\n",
        "    out_file=None,\n",
        "    feature_names=X.columns,\n",
        "    class_names=['0', '1'],\n",
        "    filled=True,\n",
        "    rounded=True,\n",
        "    special_characters=True\n",
        ")\n",
        "\n",
        "# Visualizar a árvore de decisão com Graphviz\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"decision_tree\")\n",
        "\n",
        "# Exibir a árvore renderizada\n",
        "graph.view()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "SaKuph2tY6ed",
        "outputId": "4e4aef34-c775-453f-dcc4-fd3272cf6af5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O melhor valor de max_depth é: 3\n",
            "O melhor valor de splitter é: random\n",
            "A melhor acurácia durante a validação cruzada é: 0.78\n",
            "Taxa de acerto fora da amostra: 0.80\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.91      0.87       457\n",
            "           1       0.61      0.44      0.51       143\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.72      0.68      0.69       600\n",
            "weighted avg       0.78      0.80      0.79       600\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'decision_tree.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    }
  ]
}